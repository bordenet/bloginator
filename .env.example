# ==============================================================================
# Bloginator Environment Configuration
# ==============================================================================
# INSTRUCTIONS:
#   1. Copy this file to .env: cp .env.example .env
#   2. Fill in your actual values (NEVER commit .env to git)
#   3. .env is already in .gitignore
# ==============================================================================

# ------------------------------------------------------------------------------
# Corpus and Storage
# ------------------------------------------------------------------------------
# Directory containing your historical blog posts (markdown, PDF, docx, etc.)
BLOGINATOR_CORPUS_DIR=corpus

# ChromaDB vector store directory
BLOGINATOR_CHROMA_DIR=.bloginator/chroma

# Output directory for generated content
BLOGINATOR_OUTPUT_DIR=output

# ------------------------------------------------------------------------------
# LLM Provider Configuration
# ------------------------------------------------------------------------------
# Provider: ollama, custom, openai, anthropic
BLOGINATOR_LLM_PROVIDER=ollama

# Model name (e.g., llama3, mistral, gpt-4, claude-3-opus)
BLOGINATOR_LLM_MODEL=llama3

# Base URL for LLM API (used for ollama and custom providers)
# Examples:
#   - Ollama: http://localhost:11434
#   - Custom: https://your-llm-endpoint.com/v1
#   - LM Studio: http://localhost:1234/v1
BLOGINATOR_LLM_BASE_URL=http://localhost:11434

# API key for cloud LLMs (OpenAI, Anthropic, etc.)
# BLOGINATOR_LLM_API_KEY=sk-...

# Request timeout in seconds
BLOGINATOR_LLM_TIMEOUT=120

# ------------------------------------------------------------------------------
# Custom LLM Configuration (Advanced)
# ------------------------------------------------------------------------------
# Custom headers for authentication/configuration
# Format: "Header1:Value1,Header2:Value2"
# Example: "Authorization:Bearer YOUR_TOKEN,X-Custom-Header:value"
# BLOGINATOR_LLM_CUSTOM_HEADERS=

# ------------------------------------------------------------------------------
# Generation Defaults
# ------------------------------------------------------------------------------
# Default temperature (0.0 = deterministic, 1.0 = creative)
BLOGINATOR_LLM_TEMPERATURE=0.7

# Default max tokens to generate
BLOGINATOR_LLM_MAX_TOKENS=2000

# ------------------------------------------------------------------------------
# Web UI (Optional)
# ------------------------------------------------------------------------------
# Host for web interface
BLOGINATOR_WEB_HOST=0.0.0.0

# Port for web interface
BLOGINATOR_WEB_PORT=8000

# ------------------------------------------------------------------------------
# Debug
# ------------------------------------------------------------------------------
# Enable debug logging
BLOGINATOR_DEBUG=false

# ==============================================================================
# Example Configurations
# ==============================================================================

# Example 1: Ollama (Local LLM)
# BLOGINATOR_LLM_PROVIDER=ollama
# BLOGINATOR_LLM_MODEL=llama3
# BLOGINATOR_LLM_BASE_URL=http://localhost:11434

# Example 2: LM Studio (Local LLM)
# BLOGINATOR_LLM_PROVIDER=custom
# BLOGINATOR_LLM_MODEL=local-model
# BLOGINATOR_LLM_BASE_URL=http://localhost:1234/v1

# Example 3: Custom Remote Endpoint
# BLOGINATOR_LLM_PROVIDER=custom
# BLOGINATOR_LLM_MODEL=your-model-name
# BLOGINATOR_LLM_BASE_URL=https://your-endpoint.com/api
# BLOGINATOR_LLM_CUSTOM_HEADERS="Authorization:Bearer YOUR_TOKEN"

# Example 4: OpenAI
# BLOGINATOR_LLM_PROVIDER=openai
# BLOGINATOR_LLM_MODEL=gpt-4-turbo
# BLOGINATOR_LLM_API_KEY=sk-...

# Example 5: Anthropic
# BLOGINATOR_LLM_PROVIDER=anthropic
# BLOGINATOR_LLM_MODEL=claude-3-opus-20240229
# BLOGINATOR_LLM_API_KEY=sk-ant-...
