# AI Agent Guidelines for Bloginator

This document defines coding conventions and quality standards that MUST be followed
without exception for all work on this repository.

## âš ï¸ CRITICAL: YOU ARE THE LLM âš ï¸

**WHEN GENERATING BLOGS, YOU (CLAUDE) ARE THE LLM BACKEND.**

This is NOT optional. This is HOW THE SYSTEM WORKS.

When `.env` contains `BLOGINATOR_LLM_MOCK=assistant`:
1. You run `bloginator outline` or `bloginator draft`
2. Bloginator writes requests to `.bloginator/llm_requests/request_NNNN.json`
3. **YOU read those requests and write responses to `.bloginator/llm_responses/response_NNNN.json`**
4. Bloginator reads your responses and continues

**YOU DO NOT:**
- Ask "should I use an external LLM?"
- Say "the user needs to configure an API key"
- Suggest switching to Ollama/OpenAI/Anthropic
- Write blog content directly to markdown files

**YOU DO:**
- Read each request file from `.bloginator/llm_requests/`
- Extract source material from the `prompt` field
- Synthesize content from ONLY those sources
- Write response files to `.bloginator/llm_responses/`
- Continue until all requests are answered

This is the NORMAL workflow. Acting as the LLM backend is YOUR JOB in this project.

## â›” CRITICAL: WHEN STUCK, ASK FOR PERPLEXITY HELP â›”

**The moment you get blocked or find yourself going in circles, STOP immediately.**

Do NOT continue trying random approaches. Instead:
1. **Generate a detailed Perplexity.ai prompt** for the user to run
2. Include: what you've tried, why it failed, specific technical details, environment info
3. **Wait for the user to return with Perplexity's response** before continuing
4. Fresh external research often unblocks problems that training data cannot solve

This is essential because:
- Your training data may be outdated or incomplete
- Perplexity has access to current documentation and community solutions
- The user can quickly get targeted answers for macOS/API-specific issues
- It prevents wasted time on dead-end approaches

## âš ï¸ TERMINAL OUTPUT CAPTURE ISSUES âš ï¸

After spawning many terminal sessions (60+), VS Code terminal output capture can fail.
Commands execute successfully but programmatic reads return empty.

**Workaround: Use file-based output instead of terminal capture:**
```bash
# Instead of reading terminal output directly:
python3 script.py > /tmp/output.txt 2>&1
# Then read /tmp/output.txt via the view tool
```

**Best practices:**
- Limit concurrent terminals to 3-5 sessions
- Use file redirection for any output you need to parse
- If terminal capture fails, dispose and recreate the terminal
- Consider `terminal.integrated.enablePersistentSessions: false` in VS Code settings

## â›”â›”â›” CRITICAL: NEVER BYPASS THE CORPUS â›”â›”â›”

**THIS IS THE MOST IMPORTANT RULE IN THIS DOCUMENT.**
**VIOLATION OF THIS RULE IS A COMPLETE AND UTTER FAILURE LEADING TO UNTRUSTWORTHY AI SLOP.**

When generating blog content, you MUST use the bloginator pipeline with corpus search.
NEVER write blog content directly from your training data. The entire purpose of this project is to generate from corpus in the author's voice.

### Why This Matters

The ENTIRE PURPOSE of bloginator is to generate content that:
1. Reflects the user's documented knowledge in the corpus
2. Matches the user's writing voice (voice scoring)
3. Uses the user's specific terminology and examples
4. Is grounded in RAG search results from the corpus

Content generated from your training data is USELESS because:
- It doesn't reflect the user's actual practices
- It doesn't match the user's voice
- It's generic "industry standard" content
- It defeats the entire purpose of this project

### â›” NEVER CREATE HARDCODED RESPONSE SCRIPTS â›”

**DO NOT create scripts like `tmp/batch_responses.py` with hardcoded content.**

This is the WORST possible failure mode because:
1. It looks like it works (files get created, drafts get generated)
2. But the content is FABRICATED from training data, not corpus
3. The user cannot distinguish fake content from real corpus synthesis
4. It defeats the ENTIRE PURPOSE of this project

**If you find yourself writing a script with hardcoded response content, STOP.**
That content should come from READING THE REQUEST FILES and SYNTHESIZING FROM THE
CORPUS CONTENT inside them.

### How to Generate Blog Content Correctly

**ALWAYS use one of these approaches:**

1. **Interactive mode** (user provides LLM responses):
   ```bash
   BLOGINATOR_LLM_MOCK=interactive bloginator outline --index .bloginator/chroma \
       --title "Topic Title" --keywords "keyword1,keyword2,keyword3" -o outline.json
   BLOGINATOR_LLM_MOCK=interactive bloginator draft --index .bloginator/chroma \
       --outline outline.json -o draft.md
   ```

2. **Assistant mode** (Claude acts as LLM backend):
   ```bash
   BLOGINATOR_LLM_MOCK=assistant bloginator outline --index .bloginator/chroma \
       --title "Topic Title" --keywords "keyword1,keyword2" -o outline.json
   # Then read requests from .bloginator/llm_requests/
   # Write responses to .bloginator/llm_responses/
   # Responses MUST be based on corpus search results in the request
   ```

### How to Act as the LLM Backend (Option C - The Correct Way)

When using assistant mode, Claude must:

1. **Read each request file** in `.bloginator/llm_requests/request_NNNN.json`
2. **Extract the source material** from the `prompt` field (look for `[Source 1]`, `[Source 2]`, etc.)
3. **Synthesize content** from ONLY those sources using `prompts/corpus-synthesis-llm.md` guidelines
4. **Write response files** to `.bloginator/llm_responses/response_NNNN.json`

**Response file format:**
```json
{
  "content": "The synthesized prose from corpus sources...",
  "prompt_tokens": 1500,
  "completion_tokens": 300,
  "finish_reason": "stop"
}
```

**CRITICAL: The `content` field must contain prose synthesized from the [Source N] sections
in the request's prompt. If you write content that doesn't trace to those sources,
you have failed.**

**NEVER do this:**
- Write markdown files directly with `save-file` for blog content
- Generate content from your training data
- Skip the corpus search step
- Take shortcuts for speed

### If You're Tempted to Shortcut

STOP. Ask the user how they want to proceed. Options:
- Wait for interactive mode (slower but correct)
- Use assistant mode (you act as LLM, reading corpus results)
- Batch process with a script

Speed is NOT worth generating useless content.

## CRITICAL: Repository Cleanliness

### Temporary Files Policy

- ALL temporary/experimental scripts go in `tmp/` directory (git-ignored)
- ALL blog generation outputs go in `blogs/` directory (git-ignored)
- ALL prompt experiments go in `prompts/experimentation/` (git-ignored)
- ALL context handoff prompts go in `prompts/` (e.g., `prompts/finish-refactoring-options-b-c.md`)
- NEVER create shell scripts or markdown files in the repository root
- Exception: Only permanent, maintained scripts/docs belong in root

### Markdown Documentation Policy

- Keep all working markdown files in `docs/` updated as you work
- Create index files (e.g., `docs/IMPLEMENTATION_PLAN_TOPIC_DRIFT_FIX.md`) that reference other docs
- Write comprehensive prompts to `prompts/` for context handoffs
- Reference prompt files instead of pasting huge inline content
- Each prompt should be 200-400 lines max, focused on execution steps

## CRITICAL: LLM Mode Configuration

### Available LLM Modes

The `BLOGINATOR_LLM_MOCK` environment variable controls LLM behavior:

| Value | Client | Use Case |
|-------|--------|----------|
| `true` | `MockLLMClient` | Unit tests - returns canned responses |
| `interactive` | `InteractiveLLMClient` | Human-in-the-loop via terminal prompts |
| `assistant` | `AssistantLLMClient` | File-based communication for AI agents |
| *(unset)* | Real LLM client | Production use with Ollama/OpenAI/Anthropic |

**Note**: `BLOGINATOR_LLM_MOCK` takes precedence over `BLOGINATOR_LLM_PROVIDER`.

### Assistant Mode (Claude as the LLM)

When `BLOGINATOR_LLM_MOCK=assistant`:
1. Bloginator writes requests to `.bloginator/llm_requests/request_NNNN.json`
2. Bloginator waits for `.bloginator/llm_responses/response_NNNN.json`
3. Claude (or another AI agent) reads requests and writes responses

**CRITICAL: Use the synthesis prompt at `prompts/corpus-synthesis-llm.md`** when generating responses. This prompt defines:
- How to synthesize corpus results into cohesive prose
- Quality markers and anti-patterns
- Output length guidelines
- Success metrics

To act as the LLM backend:
1. Set `BLOGINATOR_LLM_MOCK=assistant` in `.env`
2. Run a bloginator command (e.g., `bloginator outline --index .bloginator/chroma --title "Topic" --keywords "key1,key2" -o outline.json`)
3. Monitor `.bloginator/llm_requests/` for new request files
4. Read the request, apply `prompts/corpus-synthesis-llm.md` guidelines, write to `.bloginator/llm_responses/`

### Demo Script

`scripts/respond-to-llm-requests.py` provides **template-based** responses for demos.
It does NOT use any LLM - just hardcoded content for specific topics.

### No External LLM Required

- The user does NOT have external LLM API keys configured
- For testing, use `BLOGINATOR_LLM_MOCK=true` (canned responses)
- For real generation, Claude can act as the LLM via assistant mode
- NEVER switch to Ollama or other LLMs without explicit user request

## CRITICAL: Documentation Standards

### No Hyperbolic Language

NEVER use sensational or marketing language in documentation:

- **Banned phrases**: "production-grade", "world-class", "game-changing", "revolutionary",
  "cutting-edge", "unparalleled", "best-in-class", "enterprise-ready"
- **Instead**: Use factual, specific descriptions of what the code does
- **Example**: "Handles 1000 documents/minute" not "blazing fast performance"

## Mandatory Coding Standards

### Python Style Guide

All Python code MUST comply with `docs/PYTHON_STYLE_GUIDE.md`. Key requirements:

- **Line length**: 100 characters maximum (enforced by Black/Ruff)
- **Type annotations**: Required on all function parameters, return values, and class attributes
- **Docstrings**: Google style, required for all public modules, classes, and functions
- **Function length**: Target â‰¤50 lines, maximum 100 lines
- **Parameters**: â‰¤5 per function, use dataclass/dict for more
- **Import order**: stdlib â†’ third-party â†’ local (enforced by isort)
- **Max file length**: 350 lines maximum. Strive for ~250 lines

## Mandatory Quality Gates

All code MUST pass these checks before commit or PR:

```bash
# Format check (automatic in CI)
ruff check src/bloginator tests
black --check src/bloginator tests
isort --check-only src/bloginator tests

# Type checking
mypy src/bloginator/models src/bloginator/extraction src/bloginator/search \
     src/bloginator/safety src/bloginator/export src/bloginator/services \
     src/bloginator/indexing/indexer.py src/bloginator/generation \
     src/bloginator/utils/parallel.py

# Docstring checking
pydocstyle src/bloginator

# Tests with coverage
pytest --cov=src/bloginator --cov-fail-under=85
```

### CI Workflow Requirements

1. **Lint and type check** - Must pass Ruff, pydocstyle, and mypy
2. **Tests** - Must pass on Python 3.10, 3.11, and 3.12 with â‰¥85% coverage
3. **Security scanning** - Bandit, pip-audit, and Safety checks run (non-blocking)
4. **Codecov** - Coverage reports uploaded to Codecov

## Development Workflow

### Before Every Commit

1. Run quality gate script: `./scripts/run-fast-quality-gate.sh`
2. Verify all tests pass: `pytest tests/unit --no-cov`
3. Fix any linting/type errors before committing

### Before Every Push

1. Run full test suite: `pytest --cov=src/bloginator`
2. Verify coverage meets threshold (â‰¥85%)
3. Ensure CI will pass by running all quality checks locally

## Code Patterns

### Error Handling

```python
# Good - descriptive with context
raise ValueError(f"Invalid file path: {path!r} (must exist)")

# Bad - vague
raise ValueError("invalid path")
```

### Type Annotations

```python
# Required pattern
def process_document(
    file_path: Path,
    *,
    include_metadata: bool = True,
    max_chunks: int = 100,
) -> list[DocumentChunk]:
    """Process a document into chunks."""
    ...
```

### Testing

```python
class TestFeatureName:
    """Tests for FeatureName functionality."""

    def test_specific_behavior(self, tmp_path: Path) -> None:
        """Specific behavior should produce expected result."""
        # Arrange
        ...
        # Act
        ...
        # Assert
        ...
```

## Project Structure

```text
src/bloginator/
  cli/           # Click CLI commands
  export/        # Document exporters (HTML, Markdown, DOCX, PDF)
  extraction/    # Document chunking and metadata extraction
  generation/    # LLM clients and content generation
  indexing/      # ChromaDB vector indexing
  models/        # Pydantic models and dataclasses
  monitoring/    # Logging and metrics
  quality/       # Slop detection and quality assurance
  safety/        # Blocklist and content filtering
  search/        # Semantic search
  services/      # History and template management
tests/
  unit/          # Unit tests (fast, isolated)
  integration/   # Integration tests
  e2e/           # End-to-end workflow tests
  benchmarks/    # Performance tests
docs/
  *.md           # Documentation files
```

## Prohibited Patterns

1. **No untyped functions** - Every function must have type annotations
2. **No missing docstrings** - Public APIs must be documented
3. **No ignoring mypy errors** - Fix the issue, don't add `# type: ignore`
4. **No tests without assertions** - Every test must verify behavior
5. **No coverage exclusions without justification** - Document why `# pragma: no cover`

## Running Quality Checks

```bash
# Quick local check
source venv/bin/activate
ruff check src/bloginator tests
mypy src/bloginator/models src/bloginator/generation
pytest tests/unit -x --no-cov

# Full CI simulation
pytest --cov=src/bloginator --cov-report=term-missing
```

## Coverage Requirements

- **Minimum overall**: 85% (enforced in CI)
- **Target for new code**: 90%+
- **Critical paths**: 95%+ recommended

Current coverage: ~75% (as of 2025-12-08)

## âš ï¸ BATCH MODE BLOG GENERATION âš ï¸

When generating blogs using batch mode with assistant LLM, follow this exact procedure:

### Step 1: Count Sections FIRST

Before generating ANY responses, count the total sections in the outline:

```bash
cat blogs/OUTLINE.json | python3 -c "
import sys,json
d=json.load(sys.stdin)
sections=d.get('sections',[])
total=len(sections)
subs=sum(len(s.get('subsections',[])) for s in sections)
print(f'Total requests needed: {total + subs}')
"
```

### Step 2: Generate Matching Response Count

The response script MUST generate exactly as many responses as there are sections.
Do NOT hardcode response counts. Each outline is different:
- SDE ladder: 17 sections
- SRE ladder: 18 sections
- Manager ladder: 19 sections
- Hiring managers: 15 sections

### Step 3: Use Batch Mode Correctly

```bash
# Clear previous requests/responses
rm -rf .bloginator/llm_requests/* .bloginator/llm_responses/*

# Start draft generation in background
BLOGINATOR_LLM_MOCK=assistant bloginator draft \
    --index .bloginator/chroma \
    --outline blogs/OUTLINE.json \
    -o blogs/OUTPUT.md \
    --batch --batch-timeout 120 2>&1 &

# Wait for requests to be generated
sleep 5

# Provide responses (must match request count!)
python tmp/batch_responses.py

# Wait for completion
wait
```

### Step 4: Verify Output

After generation, verify:
1. File exists and has content
2. Tables are present (for career ladders)
3. Citation metrics are reasonable

```bash
# Check file size and table count
ls -la blogs/career-ladders/OUTPUT.md
grep -c "^|" blogs/career-ladders/OUTPUT.md
```

### Common Mistakes to Avoid

1. **Hardcoding 17 responses** - Different outlines have different section counts
2. **Not waiting for requests** - Must `sleep 5` before writing responses
3. **Running commands serially** - Use `&` and `wait` for background processes
4. **Not clearing old requests** - Always `rm -rf .bloginator/llm_requests/*` first
5. **Timeout too short** - Use `--batch-timeout 120` minimum for testing

## âš ï¸ EFFICIENCY: AVOID REPETITIVE DEBUGGING âš ï¸

### Signs You're Going in Circles

- Running the same command 3+ times expecting different results
- Waiting for output that never comes
- Terminal capture returning empty strings repeatedly

### When This Happens

1. **STOP immediately** - Don't run the same thing again
2. **Diagnose the root cause** - Check file existence, process status, error logs
3. **Use file redirection** - `command > /tmp/out.txt 2>&1` then `view /tmp/out.txt`
4. **Ask for help** - Generate a Perplexity prompt if truly stuck

### Pre-Flight Checklist Before Blog Generation

Before starting ANY blog generation task:

- [ ] Verify outline exists: `ls -la blogs/*.json`
- [ ] Count sections in outline (see Step 1 above)
- [ ] Verify index exists: `ls -la .bloginator/chroma`
- [ ] Clear old requests: `rm -rf .bloginator/llm_requests/* .bloginator/llm_responses/*`
- [ ] Verify response script matches section count

## ðŸ¤– AUTONOMOUS BLOG GENERATION (ZERO INTERVENTION)

This section enables future Claude sessions to generate blogs completely autonomously
without user intervention. Follow these steps exactly.

### Overview: The Full Blog Generation Pipeline

1. **Pick topics from `corpus/blog-topics.yaml`** - Contains all curated topics
2. **Generate outline** - Creates section structure with corpus search
3. **Generate draft** - Creates prose content with RAG from corpus
4. **Act as LLM backend** - Read request files, synthesize from sources, write responses
5. **Verify output** - Check word count, citations, voice score

### Step-by-Step: Generate One Blog Autonomously

```bash
# 1. Set the topic variables
TITLE="Your Blog Title"
KEYWORDS="keyword1,keyword2,keyword3"
AUDIENCE="engineering-leaders"  # or ic-engineers, devops-sre, all-disciplines
OUTPUT_NAME="blog-name"

# 2. Generate outline first
rm -rf .bloginator/llm_requests/* .bloginator/llm_responses/*
BLOGINATOR_LLM_MOCK=assistant bloginator outline \
  --index .bloginator/chroma \
  --title "$TITLE" \
  --keywords "$KEYWORDS" \
  --audience "$AUDIENCE" \
  -o "blogs/${OUTPUT_NAME}-outline.json" \
  --batch --batch-timeout 60 2>&1 &

# 3. Wait for requests, then provide responses (Claude reads & synthesizes)
sleep 3
# [Claude reads .bloginator/llm_requests/*.json and writes responses]

# 4. Generate draft from outline
rm -rf .bloginator/llm_requests/* .bloginator/llm_responses/*
BLOGINATOR_LLM_MOCK=assistant bloginator draft \
  --index .bloginator/chroma \
  --outline "blogs/${OUTPUT_NAME}-outline.json" \
  -o "blogs/${OUTPUT_NAME}.md" \
  --batch --batch-timeout 180 2>&1 &

# 5. Wait for requests, then provide responses
sleep 5
# [Claude reads .bloginator/llm_requests/*.json and writes responses]
```

### How Claude MUST Synthesize Responses

When reading request files, Claude MUST:

1. **Extract source material** - Look for `[Source 1]`, `[Source 2]`, etc. in the prompt
2. **Identify key concepts** - What specific terms, frameworks, metrics are in sources?
3. **Synthesize into prose** - Combine sources into flowing paragraphs
4. **Match author voice** - Use sentence structure and vocabulary from sources
5. **Never invent** - If sources don't cover something, don't make it up

**Example transformation:**

**Sources in request:**
```
[Source 1] SDE-1 engineers should focus on learning the codebase...
[Source 2] Entry-level engineers pair with seniors on complex work...
[Source 3] First year is about building foundational skills...
```

**CORRECT response (synthesized from sources):**
```json
{
  "content": "The first year as an SDE-1 centers on mastering the codebase while establishing trust through consistent delivery. New engineers tackle well-defined tasks independently while pairing with senior colleagues on complex work. This apprenticeship model accelerates skill-building.",
  "prompt_tokens": 1500,
  "completion_tokens": 60,
  "finish_reason": "stop"
}
```

**WRONG response (invented from training data):**
```json
{
  "content": "Junior developers typically spend 3-6 months onboarding. Best practices suggest code reviews and mentorship programs...",
  ...
}
```

### Voice Matching Requirements

When synthesizing, match the author's voice by:

1. **Use same terminology** - If sources say "Plan-of-Record", use that exact term
2. **Match sentence length** - Short, punchy sentences if sources are direct
3. **Preserve specific numbers** - "3 years experience" not "several years"
4. **Keep organizational terms** - "Four Quadrants", "Level 1/Level 2" as in sources
5. **Avoid AI slop** - No em-dashes (â€”), no "dive deep", no "leverage"

### Deduplication Requirements

Within each response and across sections:

1. **State each concept once** - Don't repeat the same point with different words
2. **Consolidate overlapping sources** - If sources repeat, synthesize into one statement
3. **Forward reference, don't repeat** - "As noted in the previous section" not full repeat
4. **Keep unique details** - Different examples from same concept should all appear once

### Anti-Hallucination Checklist

Before writing any response content, verify:

- [ ] Every claim traces to a `[Source N]` section
- [ ] No metrics or numbers I invented
- [ ] No examples not explicitly in sources
- [ ] No "industry standard" filler from training data
- [ ] Terminology matches sources exactly

### Quality Verification After Generation

After each blog is generated, verify:

```bash
# Check file exists and has content
ls -la blogs/OUTPUT.md
wc -w blogs/OUTPUT.md  # Should be 2000+ words for full blogs

# Check voice score and citations
head -20 blogs/OUTPUT.md  # Look for voice score in metadata

# Check for AI slop
grep -c "â€”" blogs/OUTPUT.md  # Should be 0 (no em-dashes)
grep -i "dive deep\|leverage\|game.changer" blogs/OUTPUT.md  # Should be 0
```

### Batch Generation: All Topics from blog-topics.yaml

To generate all blogs from the curated list:

```bash
# Read topics from corpus/blog-topics.yaml
# For each topic, extract: title, keywords, audience, summary, sections
# Generate outline then draft for each
# See corpus/blog-topics.yaml for full list
```

**Priority order:**
1. Career ladders (SDE, SRE, MGR) - Already have outlines
2. Recruiting series (8 topics)
3. Agile rituals series (12 topics)
4. Operational excellence series (15 topics)
5. Culture & leadership series (20 topics)

---

## Superpowers Skills

At the START of every conversation, run:

```bash
node ~/.codex/superpowers-augment/superpowers-augment.js bootstrap
```

This loads available skills. Key skills:
- `superpowers:brainstorming` - Before creative/feature work
- `superpowers:systematic-debugging` - Before fixing bugs
- `superpowers:test-driven-development` - Before writing implementation
- `superpowers:verification-before-completion` - Before claiming done
- `superpowers:writing-plans` - Before multi-step tasks

**To load a skill:**
```bash
node ~/.codex/superpowers-augment/superpowers-augment.js use-skill superpowers:<skill-name>
```

**To list all skills:**
```bash
node ~/.codex/superpowers-augment/superpowers-augment.js find-skills
```

**The Rule:** IF A SKILL APPLIES TO YOUR TASK (even 1% chance), YOU MUST INVOKE IT.

---

## Command Reference for AI Agents

This section provides standardized commands and workflows for AI agents working on this repository.

### Pre-Flight Checklist

Before ANY work:

```bash
# 1. Check current branch and status
git status
git log --oneline -3

# 2. Verify environment
python --version              # Should be 3.10+
which python3.11 || which python3.12
source venv/bin/activate
pip list | grep -E "black|ruff|mypy|pytest"

# 3. Verify repo health
ls -la .bloginator/           # Index directory exists
ls tests/ | head -5           # Tests present
```

### Code Quality Commands

**Quick Quality Check (Before Commits):**

```bash
./scripts/run-fast-quality-gate.sh
```

This runs:
- Black formatting check
- Ruff linting (includes import sorting via I rules)
- MyPy type checking (key modules)
- Fast unit tests

**Full Quality Check (Before PRs):**

```bash
# Format code
black --line-length=100 src/ tests/

# Fix linting issues
ruff check --fix src/ tests/

# Type checking (all modules with strict enabled)
mypy \
    src/bloginator/models \
    src/bloginator/extraction \
    src/bloginator/search \
    src/bloginator/safety \
    src/bloginator/export \
    src/bloginator/services \
    src/bloginator/indexing/indexer.py \
    src/bloginator/generation \
    src/bloginator/utils/parallel.py

# Docstring checking
pydocstyle src/bloginator/

# Security scanning
bandit -r src/bloginator/ --skip B101,B601

# Full test suite with coverage
pytest tests/ --cov=src/bloginator --cov-fail-under=85 -v
```

### Testing Commands

**Run All Tests:**

```bash
# Full test suite with coverage report
pytest tests/ -v --cov=src/bloginator --cov-report=term-missing

# Specific test file
pytest tests/unit/models/test_document.py -v

# Specific test class
pytest tests/unit/models/test_document.py::TestDocument -v

# Specific test
pytest tests/unit/models/test_document.py::TestDocument::test_constructor -v

# Fast tests only (skip slow/integration)
pytest tests/ -m "not slow" -q

# Integration tests only
pytest tests/integration/ -v

# E2E tests only
pytest tests/e2e/ -v
```

**Coverage Analysis:**

```bash
# Generate coverage report
pytest tests/ --cov=src/bloginator --cov-report=html

# View coverage report (opens in browser)
open htmlcov/index.html

# Coverage summary
pytest tests/ --cov=src/bloginator --cov-report=term-missing | tail -20
```

### Development Commands

**Setup Development Environment:**

```bash
# Clone and setup
git clone https://github.com/bordenet/bloginator.git
cd bloginator

# Create virtualenv (choose Python 3.11 or 3.12)
python3.11 -m venv venv
source venv/bin/activate

# Install with dev dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Verify setup
python -c "import bloginator; print(bloginator.__version__)"
./scripts/run-fast-quality-gate.sh
```

**Linting and Formatting:**

```bash
# Format all code (auto-fix)
black --line-length=100 src/ tests/

# Lint and fix
ruff check --fix src/ tests/

# Check only (no auto-fix)
black --check src/ tests/
ruff check src/ tests/
```

**Type Checking:**

```bash
# Strict type checking (high-value modules)
mypy src/bloginator/models \
      src/bloginator/extraction \
      src/bloginator/search

# Full mypy output with detailed errors
mypy src/bloginator/models --show-traceback

# Check specific file
mypy src/bloginator/models/document.py
```

### Git Workflow Commands

**Feature Branch Workflow:**

```bash
# Start new feature
git checkout -b feature/my-feature-name

# Check status
git status

# Stage changes
git add src/

# Commit with conventional message
git commit -m "feat(module): description of change"
# or
git commit -m "fix(module): description of bug fix"
# or
git commit -m "docs(module): documentation update"

# Push for review
git push origin feature/my-feature-name

# Create pull request (on GitHub)
# Add description, link issues, request reviewers
```

**Commit Message Format:**

Always use Conventional Commits:

```
<type>(<scope>): <subject>

<body>

<footer>
```

**Types**: feat, fix, docs, style, refactor, test, chore, perf, ci
**Scope**: module name (e.g., `generation`, `search`, `cli`)
**Subject**: Imperative, no capitals, no period

**Examples**:
```bash
git commit -m "feat(generation): add voice matching score"
git commit -m "fix(search): handle empty corpus gracefully"
git commit -m "test(extraction): add docx corruption tests"
git commit -m "docs(readme): update installation instructions"
```

### Debugging Commands

**Enable Verbose Logging:**

```bash
# Set debug logging
export BLOGINATOR_DEBUG=1

# Or in code:
import logging
logging.basicConfig(level=logging.DEBUG)
```

**Inspect CLI Commands:**

```bash
# Show help for any command
bloginator --help
bloginator extract --help
bloginator index --help
bloginator search --help
bloginator outline --help
bloginator draft --help

# Run with verbose output
bloginator search --index .bloginator/chroma "test query" -v

# Dry run (no side effects)
bloginator extract ~/writing --dry-run
```

**Check Configuration:**

```bash
# View environment variables
env | grep BLOGINATOR

# Check .env file
cat .env | grep -v "^#" | grep -v "^$"

# Verify index exists
ls -la .bloginator/
ls -la .bloginator/chroma/

# Test search index
bloginator search .bloginator/chroma "engineering" -n 5
```

### Repository Maintenance

**Clean Up:**

```bash
# Remove cache directories
rm -rf .pytest_cache/
rm -rf .mypy_cache/
rm -rf .ruff_cache/

# Remove build artifacts
rm -rf build/ dist/ *.egg-info/

# Remove test outputs
rm -rf htmlcov/ .coverage

# Clean Python cache
find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
```

**Verify Repository Health:**

```bash
# Check root directory cleanliness
./scripts/check-root-cleanliness.sh

# Validate monorepo structure
./scripts/validate-monorepo.sh

# Check cross-references in docs
./scripts/validate-cross-references.sh
```

### Common Issues & Troubleshooting

**Tests Fail with Import Errors:**

```bash
# Reinstall in editable mode
pip install -e ".[dev]" --force-reinstall

# Clear cache
rm -rf .pytest_cache/ __pycache__/

# Run tests again
pytest tests/ -x
```

**Type Checking Fails:**

```bash
# Check specific module
mypy src/bloginator/models --show-traceback

# Ignore specific error (temporary, document why)
# Add to file: # type: ignore[error-code]

# Fix the issue instead:
# Don't add type: ignore, fix the underlying type issue
```

**Pre-commit Hook Fails:**

```bash
# Check what pre-commit is doing
pre-commit run --all-files --verbose

# Fix issues
black src/ tests/
ruff check --fix src/ tests/

# Commit again
git commit -m "fix: formatting"
```

### Code Review Checklist

Before requesting review or reviewing PRs:

- [ ] All tests pass: `pytest tests/ --cov=src/bloginator`
- [ ] Linting passes: `./scripts/run-fast-quality-gate.sh`
- [ ] Type checking passes: `mypy src/bloginator/models ...`
- [ ] Coverage â‰¥85%: Check coverage report
- [ ] Docstrings added: All public functions documented
- [ ] No `type: ignore` without justification
- [ ] No untested code paths
- [ ] No hardcoded values (use config)
- [ ] Commit message follows Conventional Commits

### Quick Reference Table

| Task | Command |
|------|---------|
| **Setup** | `python3.11 -m venv venv && source venv/bin/activate && pip install -e ".[dev]"` |
| **Quick check** | `./scripts/run-fast-quality-gate.sh` |
| **Full check** | `pytest tests/ --cov=src/bloginator && mypy src/bloginator/models ...` |
| **Format** | `black --line-length=100 src/ tests/` |
| **Lint** | `ruff check --fix src/ tests/` |
| **Tests** | `pytest tests/ -v --cov=src/bloginator` |
| **Type check** | `mypy src/bloginator/models src/bloginator/extraction ...` |
| **Run command** | `bloginator extract/index/search/outline/draft` |
| **Help** | `bloginator --help` |
| **Cleanup** | `rm -rf .pytest_cache/ .mypy_cache/ .ruff_cache/ htmlcov/` |
